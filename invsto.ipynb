{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6fd5da-bc02-49ec-8985-636a11ac6488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Missing Values:\n",
      " Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "\n",
      "Outliers:\n",
      " Date\n",
      "2023-01-02    False\n",
      "2023-01-03    False\n",
      "2023-01-04    False\n",
      "2023-01-05    False\n",
      "2023-01-06    False\n",
      "              ...  \n",
      "2023-12-22    False\n",
      "2023-12-26    False\n",
      "2023-12-27    False\n",
      "2023-12-28    False\n",
      "2023-12-29    False\n",
      "Length: 245, dtype: bool\n",
      "\n",
      "Data Types:\n",
      " Open         float64\n",
      "High         float64\n",
      "Low          float64\n",
      "Close        float64\n",
      "Adj Close    float64\n",
      "Volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "##################################################\"\"TASK 1\"\"##################################################\n",
    "\n",
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Function to fetch stock data\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return stock_data\n",
    "\n",
    "# Define parameters\n",
    "ticker_adani = \"ADANIPORTS.NS\"  # Ticker for Adani Ports and Special Economic Zone Ltd\n",
    "start_date_adani = \"2023-01-01\"\n",
    "end_date_adani = \"2023-12-31\"\n",
    "\n",
    "# Task 1: Data Ingestion\n",
    "# Fetch OHLC data for Adani Ports\n",
    "data_adani = fetch_stock_data(ticker_adani, start_date_adani, end_date_adani)\n",
    "\n",
    "# Task 2: Data Validation\n",
    "# Check for missing values\n",
    "missing_values_adani = data_adani.isnull().sum()\n",
    "\n",
    "# Check for outliers using Z-score\n",
    "outliers_adani = (np.abs(zscore(data_adani.select_dtypes(include=[np.number]))) > 3).all(axis=1)\n",
    "\n",
    "# Check data types consistency\n",
    "data_types_adani = data_adani.dtypes\n",
    "\n",
    "# Task 3: Standardize Data Format\n",
    "# Ensure the data is in a common format like a pandas DataFrame\n",
    "data_adani.index = pd.to_datetime(data_adani.index)\n",
    "\n",
    "# Display the results\n",
    "print(\"Missing Values:\\n\", missing_values_adani)\n",
    "print(\"\\nOutliers:\\n\", outliers_adani)\n",
    "print(\"\\nData Types:\\n\", data_types_adani)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1846ccc9-1ef5-4827-97aa-441cb4caef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date format: None\n",
      "\n",
      "Cleaned Data:\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2023-01-02  823.000000  826.750000  816.299988  822.299988  816.808838   \n",
      "2023-01-03  822.250000  826.400024  817.799988  820.450012  814.971191   \n",
      "2023-01-04  820.799988  822.000000  806.500000  810.000000  804.591003   \n",
      "2023-01-05  814.049988  821.599976  797.000000  819.599976  814.126831   \n",
      "2023-01-06  819.900024  824.400024  803.500000  806.099976  800.716980   \n",
      "\n",
      "             Volume  \n",
      "Date                 \n",
      "2023-01-02  2042294  \n",
      "2023-01-03  2166531  \n",
      "2023-01-04  3260112  \n",
      "2023-01-05  3119740  \n",
      "2023-01-06  2892006  \n"
     ]
    }
   ],
   "source": [
    "##################################################\"\"TASK 2\"\"##################################################\n",
    "# Task 2: Data Cleaning\n",
    "\n",
    "# 1. Handle Missing Values:\n",
    "# Check for missing values\n",
    "missing_values_adani = data_adani.isnull().sum()\n",
    "\n",
    "# If missing values exist, you can decide on a strategy (e.g., imputation or removal) and implement it.\n",
    "# For demonstration purposes, let's fill missing values with the mean.\n",
    "data_adani_cleaned = data_adani.fillna(data_adani.mean())\n",
    "\n",
    "# 2. Detect and Correct Outliers:\n",
    "# Check for outliers using Z-score\n",
    "outliers_adani = (np.abs(zscore(data_adani_cleaned.select_dtypes(include=[np.number]))) > 3).all(axis=1)\n",
    "\n",
    "# If outliers are present, decide on a method to correct them (e.g., trimming or winsorizing).\n",
    "# For demonstration purposes, we'll replace outliers with the median in each column.\n",
    "for column in data_adani_cleaned.columns:\n",
    "    median_value = data_adani_cleaned[column].median()\n",
    "    data_adani_cleaned.loc[outliers_adani, column] = median_value\n",
    "\n",
    "\n",
    "# Timestamps and Date Formats:\n",
    "# Check the format of the date/timestamps\n",
    "print(\"Date format:\", data_adani_cleaned.index.inferred_freq)\n",
    "\n",
    "# If formats are inconsistent, standardize the date format\n",
    "data_adani_cleaned.index = pd.to_datetime(data_adani_cleaned.index)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(\"\\nCleaned Data:\\n\", data_adani_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d71a93a8-bdfd-4d28-964e-276b73b0ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data:\n",
      "                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2023-06-20  738.000000  742.000000  730.200012  737.799988  732.873108   \n",
      "2023-06-21  739.900024  753.250000  733.299988  749.450012  744.445312   \n",
      "2023-06-22  755.000000  758.000000  741.000000  745.599976  740.621033   \n",
      "2023-06-23  741.000000  741.000000  703.000000  714.299988  709.530029   \n",
      "2023-06-26  710.000000  726.299988  705.099976  724.400024  719.562622   \n",
      "\n",
      "              Volume      SMA_20  Rolling_mean  Upper_band  Lower_band  \\\n",
      "Date                                                                     \n",
      "2023-06-20   6753358  736.379996    736.379996  750.245802  722.514189   \n",
      "2023-06-21   9312613  737.939996    737.939996  750.137445  725.742547   \n",
      "2023-06-22  10061086  738.994995    738.994995  749.876904  728.113086   \n",
      "2023-06-23  15398550  738.367496    738.367496  752.999418  723.735573   \n",
      "2023-06-26   5696079  737.712497    737.712497  753.624754  721.800239   \n",
      "\n",
      "                  RSI  Volatility Price_Pattern  \n",
      "Date                                             \n",
      "2023-06-20  49.197870    0.000000      Downward  \n",
      "2023-06-21  62.375542    0.000000        Upward  \n",
      "2023-06-22  56.465508    0.014798      Downward  \n",
      "2023-06-23  37.588662    0.029248      Downward  \n",
      "2023-06-26  39.726035    0.026858        Upward  \n"
     ]
    }
   ],
   "source": [
    "##################################################\"\"TASK 3\"\"##################################################\n",
    "\n",
    "# Task 3: Data Transformation\n",
    "\n",
    "# 1. Calculate Technical Indicators\n",
    "# Example: Simple Moving Average (SMA)\n",
    "data_adani_cleaned['SMA_20'] = data_adani_cleaned['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Example: Bollinger Bands\n",
    "window = 20\n",
    "data_adani_cleaned['Rolling_mean'] = data_adani_cleaned['Close'].rolling(window=window).mean()\n",
    "data_adani_cleaned['Upper_band'] = data_adani_cleaned['Rolling_mean'] + 2 * data_adani_cleaned['Close'].rolling(window=window).std()\n",
    "data_adani_cleaned['Lower_band'] = data_adani_cleaned['Rolling_mean'] - 2 * data_adani_cleaned['Close'].rolling(window=window).std()\n",
    "\n",
    "# Example: Relative Strength Index (RSI)\n",
    "delta = data_adani_cleaned['Close'].diff()\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "average_gain = gain.rolling(window=14).mean()\n",
    "average_loss = loss.rolling(window=14).mean()\n",
    "\n",
    "rs = average_gain / average_loss\n",
    "data_adani_cleaned['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Drop rows with NaN values introduced by rolling windows\n",
    "data_adani_cleaned.dropna(inplace=True)\n",
    "\n",
    "# 2. Apply Feature Engineering\n",
    "# Example: Volatility Measure (Standard Deviation)\n",
    "data_adani_cleaned['Volatility'] = data_adani_cleaned['Close'].pct_change().rolling(window=20, min_periods=1).std().fillna(0)\n",
    "data_adani_cleaned['Volatility'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Example: Price Pattern (Upward or Downward Movement)\n",
    "data_adani_cleaned['Price_Pattern'] = np.where(data_adani_cleaned['Close'] > data_adani_cleaned['Open'], 'Upward', 'Downward')\n",
    "\n",
    "# 3. Resample the Data\n",
    "# Example: Resample to hourly frequency\n",
    "hourly_data = data_adani_cleaned.resample('H').ffill()\n",
    "\n",
    "# Display the transformed data\n",
    "print(\"\\nTransformed Data:\\n\", data_adani_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da0ccd07-76a4-4c87-b578-d0c7140f7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FFF\n",
      "======================================================================\n",
      "FAIL: test_calculation_correctness (__main__.TestDataValidation)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/d1/0sq30c3568xgm1scfrbs_jdr0000gn/T/ipykernel_1483/3838290656.py\", line 35, in test_calculation_correctness\n",
      "    self.assertAlmostEqual(first_row_sma_actual, first_row_sma_expected, delta=tolerance)\n",
      "AssertionError: 731.9225036621094 != 732.2425018310547 within 1e-05 delta (0.31999816894528976 difference)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_data_integrity (__main__.TestDataValidation)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/d1/0sq30c3568xgm1scfrbs_jdr0000gn/T/ipykernel_1483/3838290656.py\", line 23, in test_data_integrity\n",
      "    self.assertEqual(len(data_adani_cleaned), len(data_adani))\n",
      "AssertionError: 131 != 245\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_resampling (__main__.TestDataValidation)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/d1/0sq30c3568xgm1scfrbs_jdr0000gn/T/ipykernel_1483/3838290656.py\", line 46, in test_resampling\n",
      "    self.assertEqual(len(hourly_data), expected_length)\n",
      "AssertionError: 4609 != 100\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "FAILED (failures=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected SMA: 732.2425018310547\n",
      "Actual SMA: 731.9225036621094\n",
      "Length of cleaned data: 131\n",
      "Length of original data: 245\n",
      "Length of resampled data: 4609\n",
      "Expected length: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=3>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\"\"TASK 4\"\"##################################################\n",
    "\n",
    "import pytest\n",
    "\n",
    "# Example SMA calculation\n",
    "window_size = 20\n",
    "data_adani_cleaned['SMA_20'] = data_adani_cleaned['Close'].rolling(window=window_size).mean()\n",
    "\n",
    "# Define first_row_sma_expected after calculating SMA\n",
    "first_row_sma_expected = data_adani_cleaned['SMA_20'].iloc[window_size - 1]\n",
    "\n",
    "class TestDataValidation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Initialize data or load it from a test file\n",
    "        pass\n",
    "\n",
    "    def test_data_integrity(self):\n",
    "        # Print relevant information for debugging\n",
    "        print(\"Length of cleaned data:\", len(data_adani_cleaned))\n",
    "        print(\"Length of original data:\", len(data_adani))\n",
    "\n",
    "        # Check if the length of cleaned data matches original data\n",
    "        self.assertEqual(len(data_adani_cleaned), len(data_adani))\n",
    "\n",
    "    def test_calculation_correctness(self):\n",
    "        # Calculate the actual SMA for the first row\n",
    "        first_row_sma_actual = data_adani_cleaned['SMA_20'].iloc[window_size]\n",
    "\n",
    "        # Print relevant information for debugging\n",
    "        print(\"Expected SMA:\", first_row_sma_expected)\n",
    "        print(\"Actual SMA:\", first_row_sma_actual)\n",
    "\n",
    "        # Define a tolerance value (adjust as needed)\n",
    "        tolerance = 1e-5\n",
    "        self.assertAlmostEqual(first_row_sma_actual, first_row_sma_expected, delta=tolerance)\n",
    "\n",
    "    def test_resampling(self):\n",
    "        # Define an expected length for resampled data\n",
    "        expected_length = 100  # Adjust this value based on your expectations\n",
    "\n",
    "        # Print relevant information for debugging\n",
    "        print(\"Length of resampled data:\", len(hourly_data))\n",
    "        print(\"Expected length:\", expected_length)\n",
    "\n",
    "        # Check if resampled data has the expected length and format\n",
    "        self.assertEqual(len(hourly_data), expected_length)\n",
    "\n",
    "        # Update the set of expected columns based on your transformation\n",
    "        expected_columns = {'Open', 'High', 'Low', 'Close', 'SMA_20', 'Volatility', 'Price_Pattern'}\n",
    "        self.assertSetEqual(set(hourly_data.columns), expected_columns)\n",
    "\n",
    "# Create a test suite\n",
    "test_suite = unittest.TestLoader().loadTestsFromTestCase(TestDataValidation)\n",
    "\n",
    "# Run the test suite\n",
    "unittest.TextTestRunner().run(test_suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ba297-34a2-4331-86a0-99901dd448d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
